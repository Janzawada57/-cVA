{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EdQaI5Dj8VWIDHoUS6LHJS2hBuYG5XJw",
      "authorship_tag": "ABX9TyN4uiVuyCXTb2RBdbSlDNEv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Janzawada57/-cVA/blob/main/untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from datetime import datetime\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def main():\n",
        "    coin = 'BTC-USD'\n",
        "    minutes_to_wait = 60\n",
        "    prices = []\n",
        "    while True:\n",
        "        current_price = get_current_price(coin)\n",
        "        prices.append(current_price)\n",
        "        print(prices)  # wyświetlenie aktualnej listy cen\n",
        "        if len(prices) >= 2:\n",
        "            trend = analyze_trend(prices)\n",
        "            if trend == 'up':\n",
        "                print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \" - Buy signal!\")\n",
        "            elif trend == 'down':\n",
        "                print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \" - Sell signal!\")\n",
        "        if len(prices) > 10:\n",
        "            prices.pop(0)\n",
        "        time.sleep(minutes_to_wait * 60)\n",
        "\n",
        "# przykładowe dane wejściowe dla modelu\n",
        "x = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
        "y = np.array([0, 1])\n",
        "\n",
        "# tworzenie modelu sieci neuronowej\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(10, input_shape=(5,), activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# kompilacja modelu\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# trenowanie modelu\n",
        "model.fit(x, y, epochs=10, batch_size=32)\n",
        "\n",
        "# przykładowe użycie biblioteki sklearn do klasyfikacji\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(x, y)\n",
        "\n",
        "# funkcje do pobierania aktualnej ceny i analizowania trendu\n",
        "def get_current_price(coin):\n",
        "    URL = \"https://api.coinbase.com/v2/prices/{}/buy\"\n",
        "    response = requests.get(URL.format(coin))\n",
        "    response_json = json.loads(response.text)\n",
        "    return float(response_json['data']['amount'])\n",
        "\n",
        "def analyze_trend(price_list):\n",
        "    trend = None\n",
        "    if price_list[-2] < price_list[-1]:\n",
        "        trend = 'up'\n",
        "    elif price_list[-2] > price_list[-1]:\n",
        "        trend = 'down'\n",
        "    return trend\n",
        "\n"
      ],
      "metadata": {
        "id": "1UvY6fNtfJgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e544cbf-b57c-4b65-f38e-bcd4662b273d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 2.8469 - accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8031 - accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7594 - accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7160 - accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.6728 - accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.6298 - accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.5871 - accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.5496 - accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.5218 - accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.4941 - accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from datetime import datetime\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# funkcje do pobierania aktualnej ceny i analizowania trendu\n",
        "def get_current_price(coin):\n",
        "    URL = \"https://api.coinbase.com/v2/prices/{}/buy\"\n",
        "    response = requests.get(URL.format(coin))\n",
        "    response_json = json.loads(response.text)\n",
        "    return float(response_json['data']['amount'])\n",
        "\n",
        "def analyze_trend(price_list, model):\n",
        "    # przygotowanie danych wejściowych do modelu\n",
        "    input_data = np.array([price_list[-5:]])\n",
        "    # predykcja za pomocą modelu\n",
        "    prediction = model.predict(input_data)[0]\n",
        "    # analiza trendu na podstawie predykcji\n",
        "    trend = None\n",
        "    if prediction >= 0.5:\n",
        "        trend = 'up'\n",
        "    else:\n",
        "        trend = 'down'\n",
        "    return trend\n",
        "\n",
        "def main():\n",
        "    coin = 'BTC-USD'\n",
        "    minutes_to_wait = 60\n",
        "    prices = []\n",
        "    \n",
        "    # przygotowanie danych wejściowych dla modelu\n",
        "    x = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
        "    y = np.array([0, 1])\n",
        "\n",
        "    # tworzenie modelu sieci neuronowej\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(10, input_shape=(5,), activation='relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # kompilacja modelu\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # trenowanie modelu\n",
        "    model.fit(x, y, epochs=10, batch_size=32)\n",
        "\n",
        "    while True:\n",
        "        current_price = get_current_price(coin)\n",
        "        prices.append(current_price)\n",
        "        print(prices)  # wyświetlenie aktualnej listy cen\n",
        "        if len(prices) >= 2:\n",
        "            trend = analyze_trend(prices, model)\n",
        "            if trend == 'up':\n",
        "                print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \" - Buy signal!\")\n",
        "            elif trend == 'down':\n",
        "                print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \" - Sell signal!\")\n",
        "        if len(prices) > 10:\n",
        "            prices.pop(0)\n",
        "        time.sleep(minutes_to_wait * 60)\n"
      ],
      "metadata": {
        "id": "I8XtC1OimWUa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# stałe\n",
        "POJEMNOSC_PLECAKA = 50  # pojemność plecaka w jednostkach\n",
        "LICZBA_PRZEDMIOTOW = 20  # liczba dostępnych przedmiotów\n",
        "LICZBA_POPULACJI = 100  # liczba osobników w populacji\n",
        "LICZBA_GENERACJI = 50  # liczba generacji w algorytmie genetycznym\n",
        "PRAWDOPODOBIENSTWO_MUTACJI = 0.1  # prawdopodobieństwo mutacji\n",
        "PRAWDOPODOBIENSTWO_KRZYŻOWANIA = 0.8  # prawdopodobieństwo krzyżowania\n",
        "\n",
        "\n",
        "# funkcja celu\n",
        "def funkcja_celu(przedmioty, plecak):\n",
        "    wartosc = 0\n",
        "    waga = 0\n",
        "    for i in range(len(przedmioty)):\n",
        "        if plecak[i] == 1:\n",
        "            wartosc += przedmioty[i][0]\n",
        "            waga += przedmioty[i][1]\n",
        "    if waga > POJEMNOSC_PLECAKA:\n",
        "        wartosc = 0\n",
        "    return wartosc\n",
        "\n",
        "\n",
        "# generowanie populacji początkowej\n",
        "def generuj_populacje(przedmioty):\n",
        "    populacja = []\n",
        "    for i in range(LICZBA_POPULACJI):\n",
        "        osobnik = [random.randint(0, 1) for _ in range(LICZBA_PRZEDMIOTOW)]\n",
        "        populacja.append(osobnik)\n",
        "    return populacja\n",
        "\n",
        "\n",
        "# selekcja turniejowa\n",
        "def selekcja(populacja, przedmioty):\n",
        "    nowa_populacja = []\n",
        "    for _ in range(LICZBA_POPULACJI):\n",
        "        osobnik_1 = populacja[random.randint(0, LICZBA_POPULACJI - 1)]\n",
        "        osobnik_2 = populacja[random.randint(0, LICZBA_POPULACJI - 1)]\n",
        "        if funkcja_celu(przedmioty, osobnik_1) > funkcja_celu(przedmioty, osobnik_2):\n",
        "            nowa_populacja.append(osobnik_1)\n",
        "        else:\n",
        "            nowa_populacja.append(osobnik_2)\n",
        "    return nowa_populacja\n",
        "\n",
        "\n",
        "# krzyżowanie jednopunktowe\n",
        "def krzyzowanie(populacja):\n",
        "    nowa_populacja = []\n",
        "    for i in range(LICZBA_POPULACJI // 2):\n",
        "        if random.random() < PRAWDOPODOBIENSTWO_KRZYŻOWANIA:\n",
        "            osobnik_1 = populacja[random.randint(0, LICZBA_POPULACJI - 1)]\n",
        "            osobnik_2 = populacja[random.randint(0, LICZBA_POPULACJI - 1)]\n",
        "            punkt_przeciecia = random.randint\n"
      ],
      "metadata": {
        "id": "PNddWf5Gl1hm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "class Assistant:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.model = keras.Sequential([\n",
        "            keras.layers.Dense(128, activation='relu'),\n",
        "            keras.layers.Dense(64, activation='relu'),\n",
        "            keras.layers.Dense(32, activation='relu'),\n",
        "            keras.layers.Dense(3, activation='softmax')\n",
        "        ])\n",
        "        \n",
        "        self.intents = {\n",
        "            'greeting': ['hi', 'hello', 'hey'],\n",
        "            'farewell': ['bye', 'goodbye', 'see you'],\n",
        "            'weather': ['weather', 'temperature', 'forecast']\n",
        "        }\n",
        "        \n",
        "        self.responses = {\n",
        "            'greeting': 'Hello! How can I assist you?',\n",
        "            'farewell': 'Goodbye! Have a nice day!',\n",
        "            'weather': 'The weather in your city is sunny.'\n",
        "        }\n",
        "        \n",
        "        self.tokenizer = None\n",
        "    \n",
        "    def train(self, data):\n",
        "        # data - list of tuples (text, intent)\n",
        "        \n",
        "        # prepare training data\n",
        "        texts, intents = zip(*data)\n",
        "        self.tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "        self.tokenizer.fit_on_texts(texts)\n",
        "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
        "        X = keras.preprocessing.sequence.pad_sequences(sequences, padding='post')\n",
        "        y = keras.utils.to_categorical(intents, num_classes=3)\n",
        "        \n",
        "        # compile and fit model\n",
        "        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        self.model.fit(X, y, epochs=10, batch_size=32)\n",
        "        \n",
        "    def predict(self, text):\n",
        "        # preprocess input text\n",
        "        sequence = self.tokenizer.texts_to_sequences([text])\n",
        "        X = keras.preprocessing.sequence.pad_sequences(sequence, padding='post')\n",
        "        \n",
        "        # make prediction\n",
        "        prediction = self.model.predict(X)[0]\n",
        "        intent_index = prediction.argmax()\n",
        "        intent = list(self.intents.keys())[intent_index]\n",
        "        \n",
        "        # return response\n",
        "        return self.responses[intent]\n"
      ],
      "metadata": {
        "id": "cfP4NcOonm6Z"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from datetime import datetime\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import cv2\n",
        "from IPython.display import Image\n",
        "\n",
        "def main():\n",
        "    coin = 'BTC-USD'\n",
        "    minutes_to_wait = 60\n",
        "    prices = []\n",
        "    while True:\n",
        "        current_price = get_current_price(coin)\n",
        "        prices.append(current_price)\n",
        "        print(prices)  # wyświetlenie aktualnej listy cen\n",
        "        if len(prices) >= 2:\n",
        "            trend = analyze_trend(prices)\n",
        "            if trend == 'up':\n",
        "                print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \" - Buy signal!\")\n",
        "            elif trend == 'down':\n",
        "                print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \" - Sell signal!\")\n",
        "        if len(prices) > 10:\n",
        "            prices.pop(0)\n",
        "        time.sleep(minutes_to_wait * 60)\n",
        "\n",
        "# przykładowe dane wejściowe dla modelu\n",
        "x = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
        "y = np.array([0, 1])\n",
        "\n",
        "# tworzenie modelu sieci neuronowej\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(10, input_shape=(5,), activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# kompilacja modelu\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# trenowanie modelu\n",
        "model.fit(x, y, epochs=10, batch_size=32)\n",
        "\n",
        "# przykładowe użycie biblioteki sklearn do klasyfikacji\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(x, y)\n",
        "\n",
        "# funkcje do pobierania aktualnej ceny i analizowania trendu\n",
        "def get_current_price(coin):\n",
        "    URL = \"https://api.coinbase.com/v2/prices/{}/buy\"\n",
        "    response = requests.get(URL.format(coin))\n",
        "    response_json = json.loads(response.text)\n",
        "    return float(response_json['data']['amount'])\n",
        "\n",
        "def analyze_trend(price_list):\n",
        "    trend = None\n",
        "    if price_list[-2] < price_list[-1]:\n",
        "        trend = 'up'\n",
        "    elif price_list[-2] > price_list[-1]:\n",
        "        trend = 'down'\n",
        "    return trend\n",
        "\n",
        "# Load the pre-trained ImageNet model\n",
        "img_model = tf.keras.applications.MobileNetV2()\n",
        "\n",
        "# Define a function for taking a photo\n",
        "def take_photo():\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    ret, frame = cap.read()\n",
        "    filename = 'photo.jpg'\n",
        "    cv2.imwrite(filename, frame)\n",
        "    cap.release()\n",
        "    return filename\n",
        "\n",
        "# Define a function for analyzing the image using the ImageNet model\n",
        "# Define a function for analyzing the image using the ImageNet model\n",
        "def analyze_image(filename):\n",
        "    # Load the image\n",
        "    img = tf.keras.preprocessing.image.load_img(filename, target_size=(224, 224))\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    # Expand the dimensions of the image so that it can be fed to the model\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    # Preprocess the image\n",
        "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
        "    # Make predictions on the image using the model\n",
        "    predictions = img_model.predict(img_array)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Wm1LEcJ3j1lV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9efabf5-bd16-40f4-bc44-5d8195802aed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.4157 - accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.3964 - accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3771 - accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.3578 - accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.3386 - accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.3195 - accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.3004 - accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.2814 - accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.2625 - accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.2437 - accuracy: 0.5000\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "14536120/14536120 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "def check_sum(numbers, target_sum):\n",
        "    for subset in itertools.combinations(numbers, 3):\n",
        "        if sum(subset) == target_sum:\n",
        "            return subset\n",
        "    return None\n",
        "\n",
        "def find_numbers(numbers):\n",
        "    target_sum = sum(numbers) // 2\n",
        "    for i in range(3, len(numbers)):\n",
        "        for combination in itertools.combinations(numbers, i):\n",
        "            result = check_sum(combination, target_sum)\n",
        "            if result:\n",
        "                return result, tuple(set(numbers) - set(result))\n",
        "\n",
        "numbers = [1, 2, 3, 4, 5, 6]\n",
        "result, remaining = find_numbers(numbers)\n",
        "\n",
        "print(\"The three numbers that add up to half of the sum are:\", result)\n",
        "print(\"The remaining three numbers are:\", remaining)\n"
      ],
      "metadata": {
        "id": "QX5QW7OYwWVw",
        "outputId": "2522c1e8-d727-4bf0-e184-b8c6baddf090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The three numbers that add up to half of the sum are: (1, 3, 6)\n",
            "The remaining three numbers are: (2, 4, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# definicja danych wejściowych i oczekiwanych wyników\n",
        "x_train = np.array([[1, 2, 3, 4]])\n",
        "y_train = np.array([[1]])\n",
        "\n",
        "# definicja modelu sieci neuronowej\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# kompilacja modelu\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# trenowanie modelu\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=1)\n",
        "\n",
        "# testowanie modelu\n",
        "x_test = np.array([[2, 4, 6, 8]])\n",
        "y_test = np.array([[1]])\n",
        "loss, acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"Test accuracy:\", acc)\n"
      ],
      "metadata": {
        "id": "DZpsWpkxw-up",
        "outputId": "e3122aac-b70f-428a-f3f5-1e25c9522b67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0909 - accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0863 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0820 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0778 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0739 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0702 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0667 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0634 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0602 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0573 - accuracy: 1.0000\n",
            "1/1 - 0s - loss: 0.0033 - accuracy: 1.0000 - 225ms/epoch - 225ms/step\n",
            "Test accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# dane treningowe\n",
        "x_train = np.array([[70], [80], [90], [100], [110], [120], [130], [140], [150], [160]])\n",
        "y_train = np.array([[110000], [120000], [130000], [140000], [150000], [160000], [170000], [180000], [190000], [200000]])\n",
        "\n",
        "# model sieci neuronowej\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=(1,))\n",
        "])\n",
        "\n",
        "# kompilacja modelu\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "\n",
        "# trenowanie modelu\n",
        "model.fit(x_train, y_train, epochs=200)\n",
        "\n",
        "# prognozowanie ceny mieszkań na podstawie powierzchni\n",
        "x_test = np.array([[75], [85], [95], [105], [115], [125], [135], [145], [155], [165]])\n",
        "y_pred = model.predict(x_test)\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "id": "2N-SPVHNyFIV",
        "outputId": "83d8b4ac-2523-4631-eda6-2f5151b86214",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 24845086720.0000\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1940753584488448.0000\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 152175575877686394880.0000\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11932166876536085812346880.0000\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 935607487960057707857845420032.0000\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 73361485439928406206459407094513664.0000\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: inf\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: inf\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: inf\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: inf\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: inf\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: inf\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: inf\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: inf\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: inf\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: nan\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: nan\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: nan\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: nan\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: nan\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: nan\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: nan\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: nan\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: nan\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: nan\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: nan\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: nan\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: nan\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: nan\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: nan\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: nan\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: nan\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: nan\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: nan\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: nan\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: nan\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: nan\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: nan\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: nan\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: nan\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: nan\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: nan\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: nan\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: nan\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: nan\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: nan\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: nan\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: nan\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: nan\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: nan\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: nan\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: nan\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: nan\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: nan\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: nan\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: nan\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: nan\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: nan\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: nan\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: nan\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: nan\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: nan\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: nan\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: nan\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: nan\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: nan\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: nan\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: nan\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: nan\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: nan\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: nan\n",
            "1/1 [==============================] - 0s 255ms/step\n",
            "[[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from datetime import datetime\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def main():\n",
        "    coin = 'BTC-USD'\n",
        "    minutes_to_wait = 60\n",
        "    prices = []\n",
        "    while True:\n",
        "        current_price = get_current_price(coin)\n",
        "        prices.append(current_price)\n",
        "        print(prices)  # wyświetlenie aktualnej listy cen\n",
        "        if len(prices) >= 2:\n",
        "            trend = analyze_trend(prices)\n",
        "            if trend == 'up':\n",
        "                print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \" - Buy signal!\")\n",
        "            elif trend == 'down':\n",
        "                print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \" - Sell signal!\")\n",
        "        if len(prices) > 10:\n",
        "            prices.pop(0)\n",
        "        time.sleep(minutes_to_wait * 60)\n",
        "\n",
        "# przykładowe dane wejściowe dla modelu\n",
        "x = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
        "y = np.array([0, 1])\n",
        "\n",
        "# tworzenie modelu sieci neuronowej\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(10, input_shape=(5,), activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# kompilacja modelu\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# trenowanie modelu\n",
        "model.fit(x, y, epochs=10, batch_size=32)\n",
        "\n",
        "# przykładowe użycie biblioteki sklearn do klasyfikacji\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(x, y)\n",
        "\n",
        "# funkcje do pobierania aktualnej ceny i analizowania trendu\n",
        "def get_current_price(coin):\n",
        "    URL = \"https://api.coinbase.com/v2/prices/{}/buy\"\n",
        "    response = requests.get(URL.format(coin))\n",
        "    response_json = json.loads(response.text)\n",
        "    return float(response_json['data']['amount'])\n",
        "\n",
        "def analyze_trend(price_list):\n",
        "    trend = None\n",
        "    if price_list[-2] < price_list[-1]:\n",
        "        trend = 'up'\n",
        "    elif price_list[-2] > price_list[-1]:\n",
        "        trend = 'down'\n",
        "    return trend\n",
        "import sqlite3\n",
        "\n",
        "# Ustanowienie połączenia z bazą danych\n",
        "conn = sqlite3.connect('servers.db')\n",
        "\n",
        "# Utworzenie kursora\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Utworzenie tabeli servers\n",
        "cursor.execute('''CREATE TABLE servers\n",
        "                 (id INTEGER PRIMARY KEY, \n",
        "                  name TEXT,\n",
        "                  location TEXT,\n",
        "                  status TEXT)''')\n",
        "\n",
        "# Dodanie przykładowych danych do tabeli servers\n",
        "cursor.execute(\"INSERT INTO servers (name, location, status) VALUES ('Server1', 'USA', 'Active')\")\n",
        "cursor.execute(\"INSERT INTO servers (name, location, status) VALUES ('Server2', 'Europe', 'Inactive')\")\n",
        "cursor.execute(\"INSERT INTO servers (name, location, status) VALUES ('Server3', 'Asia', 'Active')\")\n",
        "\n",
        "# Zatwierdzenie zmian w bazie danych\n",
        "conn.commit()\n",
        "\n",
        "# Zamknięcie połączenia z bazą danych\n",
        "conn.close()\n"
      ],
      "metadata": {
        "id": "Yu8SWh9Wh28g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50fc22b1-8b94-4a58-f03f-43d3991fa408"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.2409 - accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.2114 - accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1825 - accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.1543 - accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1267 - accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1000 - accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.0740 - accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.0489 - accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.0247 - accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0014 - accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v9PgeBrPoiyz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nowa sekcja"
      ],
      "metadata": {
        "id": "kFWmU1-hgTCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install jupyterlab\n"
      ],
      "metadata": {
        "id": "VXskhZXKGcY4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee46c837-52f3-47bf-f093-2dd8c06752a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jupyterlab\n",
            "  Downloading jupyterlab-3.6.3-py3-none-any.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab-server~=2.19\n",
            "  Downloading jupyterlab_server-2.22.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from jupyterlab) (6.2)\n",
            "Requirement already satisfied: jinja2>=2.1 in /usr/local/lib/python3.9/dist-packages (from jupyterlab) (3.1.2)\n",
            "Requirement already satisfied: notebook<7 in /usr/local/lib/python3.9/dist-packages (from jupyterlab) (6.4.8)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.9/dist-packages (from jupyterlab) (2.0.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.9/dist-packages (from jupyterlab) (7.34.0)\n",
            "Collecting jupyter-server-ydoc~=0.8.0\n",
            "  Downloading jupyter_server_ydoc-0.8.0-py3-none-any.whl (11 kB)\n",
            "Collecting nbclassic\n",
            "  Downloading nbclassic-0.5.5-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-core in /usr/local/lib/python3.9/dist-packages (from jupyterlab) (5.3.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from jupyterlab) (1.24.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from jupyterlab) (23.1)\n",
            "Collecting jupyter-ydoc~=0.2.3\n",
            "  Downloading jupyter_ydoc-0.2.4-py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2>=2.1->jupyterlab) (2.1.2)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.9/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (1.8.0)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.9/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (6.5.4)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.9/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (5.7.1)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (3.6.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (0.16.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (0.17.1)\n",
            "Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.9/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (5.8.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (23.2.1)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.9/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (6.1.12)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (21.3.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.9/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (1.5.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core->jupyterlab) (3.2.0)\n",
            "Collecting jupyter-server-fileid<1,>=0.6.0\n",
            "  Downloading jupyter_server_fileid-0.9.0-py3-none-any.whl (15 kB)\n",
            "Collecting ypy-websocket<0.9.0,>=0.8.2\n",
            "  Downloading ypy_websocket-0.8.4-py3-none-any.whl (10 kB)\n",
            "Collecting y-py<0.6.0,>=0.5.3\n",
            "  Downloading y_py-0.5.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from jupyter-ydoc~=0.2.3->jupyterlab) (6.4.1)\n",
            "Collecting json5>=0.9.0\n",
            "  Downloading json5-0.9.11-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.9/dist-packages (from jupyterlab-server~=2.19->jupyterlab) (2.12.1)\n",
            "Collecting jsonschema>=4.17.3\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.28\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipykernel in /usr/local/lib/python3.9/dist-packages (from notebook<7->jupyterlab) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.9/dist-packages (from notebook<7->jupyterlab) (0.2.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.9/dist-packages (from notebook<7->jupyterlab) (1.5.6)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython->jupyterlab) (3.0.38)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython->jupyterlab) (4.4.2)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython->jupyterlab) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython->jupyterlab) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython->jupyterlab) (2.14.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython->jupyterlab) (67.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython->jupyterlab) (0.2.0)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython->jupyterlab) (4.8.0)\n",
            "Collecting notebook-shim>=0.1.0\n",
            "  Downloading notebook_shim-0.2.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.9/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->jupyter-ydoc~=0.2.3->jupyterlab) (3.15.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython->jupyterlab) (0.8.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab) (23.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.9/dist-packages (from jupyter-client>=6.1.12->jupyter-server<3,>=1.16.0->jupyterlab) (2.8.2)\n",
            "Collecting jupyter-events>=0.5.0\n",
            "  Downloading jupyter_events-0.6.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (4.9.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.2.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (1.5.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (4.11.2)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (1.2.1)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.7.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.8.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat>=5.2.0->jupyter-server<3,>=1.16.0->jupyterlab) (2.16.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython->jupyterlab) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyterlab) (0.2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->jupyterlab-server~=2.19->jupyterlab) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->jupyterlab-server~=2.19->jupyterlab) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->jupyterlab-server~=2.19->jupyterlab) (2022.12.7)\n",
            "Collecting aiosqlite<1,>=0.17.0\n",
            "  Downloading aiosqlite-0.19.0-py3-none-any.whl (15 kB)\n",
            "Collecting aiofiles<23,>=22.1.0\n",
            "  Downloading aiofiles-22.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting ypy-websocket<0.9.0,>=0.8.2\n",
            "  Downloading ypy_websocket-0.8.3-py3-none-any.whl (10 kB)\n",
            "  Downloading ypy_websocket-0.8.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab) (21.2.0)\n",
            "Collecting rfc3339-validator\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: jsonschema[format-nongpl]>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from jupyter-events>=0.5.0->jupyter-server-fileid<1,>=0.6.0->jupyter-server-ydoc~=0.8.0->jupyterlab) (4.3.3)\n",
            "Collecting python-json-logger>=2.0.4\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.9/dist-packages (from jupyter-events>=0.5.0->jupyter-server-fileid<1,>=0.6.0->jupyter-server-ydoc~=0.8.0->jupyterlab) (6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->jupyter-server<3,>=1.16.0->jupyterlab) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab) (2.21)\n",
            "\u001b[33mWARNING: jsonschema 4.3.3 does not provide the extra 'format-nongpl'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting fqdn\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting isoduration\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting jsonpointer>1.13\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab) (1.13)\n",
            "Collecting uri-template\n",
            "  Downloading uri_template-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting arrow>=0.15.0\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: y-py, json5, uri-template, rfc3986-validator, rfc3339-validator, requests, python-json-logger, jsonschema, jsonpointer, jedi, fqdn, aiosqlite, aiofiles, ypy-websocket, jupyter-ydoc, arrow, isoduration, jupyter-events, notebook-shim, jupyterlab-server, jupyter-server-fileid, nbclassic, jupyter-server-ydoc, jupyterlab\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.3.3\n",
            "    Uninstalling jsonschema-4.3.3:\n",
            "      Successfully uninstalled jsonschema-4.3.3\n",
            "Successfully installed aiofiles-22.1.0 aiosqlite-0.19.0 arrow-1.2.3 fqdn-1.5.1 isoduration-20.11.0 jedi-0.18.2 json5-0.9.11 jsonpointer-2.3 jsonschema-4.17.3 jupyter-events-0.6.3 jupyter-server-fileid-0.9.0 jupyter-server-ydoc-0.8.0 jupyter-ydoc-0.2.4 jupyterlab-3.6.3 jupyterlab-server-2.22.1 nbclassic-0.5.5 notebook-shim-0.2.2 python-json-logger-2.0.7 requests-2.28.2 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 uri-template-1.2.0 y-py-0.5.9 ypy-websocket-0.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hA24HmlU1d16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44fb4a52-30a6-4172-a654-1967bddc471e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "def Concat(a, b):\n",
        "  # Use display.JSON to transfer a structured result.\n",
        "  return IPython.display.JSON({'result': ' '.join((a, b))})\n",
        "\n",
        "output.register_callback('notebook.Concat', Concat)"
      ],
      "metadata": {
        "id": "Ga58MhS3_KUX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%javascript\n",
        "const listenerChannel = new BroadcastChannel('channel');\n",
        "listenerChannel.onmessage = (msg) => {\n",
        "  const div = document.createElement('div');\n",
        "  div.textContent = msg.data;\n",
        "  document.body.appendChild(div);\n",
        "};"
      ],
      "metadata": {
        "id": "ncZvWbBSiQ72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "166c41d3-35a9-4523-9d8d-4889841946a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "const listenerChannel = new BroadcastChannel('channel');\n",
              "listenerChannel.onmessage = (msg) => {\n",
              "  const div = document.createElement('div');\n",
              "  div.textContent = msg.data;\n",
              "  document.body.appendChild(div);\n",
              "};\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "RfoQaCzeiSVW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "def Concat(a, b):\n",
        "  # Use display.JSON to transfer a structured result.\n",
        "  return IPython.display.JSON({'result': ' '.join((a, b))})\n",
        "\n",
        "output.register_callback('notebook.Concat', Concat)"
      ],
      "metadata": {
        "id": "Dl6SjbyviUjP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the file we downloaded to /tmp\n",
        "!cat /tmp/downloaded_from_gcs.txt"
      ],
      "metadata": {
        "id": "tcOlJaO5iWvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3233328f-aefa-48cc-f464-38a2b61197b3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: /tmp/downloaded_from_gcs.txt: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%javascript\n",
        "(async function() {\n",
        "  const result = await google.colab.kernel.invokeFunction(\n",
        "    'notebook.Concat', // The callback name.\n",
        "    ['hello', 'world!'], // The arguments.\n",
        "    {}); // kwargs\n",
        "  const text = result.data['application/json'];\n",
        "  document.querySelector(\"#output-area\").appendChild(document.createTextNode(text.result));\n",
        "})();"
      ],
      "metadata": {
        "id": "tUtaAWBciUjQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d705e24a-6414-445f-df5b-842839408ce2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async function() {\n",
              "  const result = await google.colab.kernel.invokeFunction(\n",
              "    'notebook.Concat', // The callback name.\n",
              "    ['hello', 'world!'], // The arguments.\n",
              "    {}); // kwargs\n",
              "  const text = result.data['application/json'];\n",
              "  document.querySelector(\"#output-area\").appendChild(document.createTextNode(text.result));\n",
              "})();\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.HTML('''\n",
        "    The items:\n",
        "    <br><ol id=\"items\"></ol>\n",
        "    <button id='button'>Click to add</button>\n",
        "    <script>\n",
        "      document.querySelector('#button').onclick = () => {\n",
        "        google.colab.kernel.invokeFunction('notebook.AddListItem', [], {});\n",
        "      };\n",
        "    </script>\n",
        "    '''))\n",
        "\n",
        "def add_list_item():\n",
        "  # Use redirect_to_element to direct the elements which are being written.\n",
        "  with output.redirect_to_element('#items'):\n",
        "    # Use display to add items which will be persisted on notebook reload.\n",
        "    display(IPython.display.HTML('<li> Another item</li>'))\n",
        "\n",
        "output.register_callback('notebook.AddListItem', add_list_item)"
      ],
      "metadata": {
        "id": "BCIyPWPtiUjR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "765325aa-e694-42a8-eb8e-d3a88a9e38b9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    The items:\n",
              "    <br><ol id=\"items\"></ol>\n",
              "    <button id='button'>Click to add</button>\n",
              "    <script>\n",
              "      document.querySelector('#button').onclick = () => {\n",
              "        google.colab.kernel.invokeFunction('notebook.AddListItem', [], {});\n",
              "      };\n",
              "    </script>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "import uuid\n",
        "from google.colab import output\n",
        "\n",
        "class InvokeButton(object):\n",
        "  def __init__(self, title, callback):\n",
        "    self._title = title\n",
        "    self._callback = callback\n",
        "\n",
        "  def _repr_html_(self):\n",
        "    callback_id = 'button-' + str(uuid.uuid4())\n",
        "    output.register_callback(callback_id, self._callback)\n",
        "\n",
        "    template = \"\"\"<button id=\"{callback_id}\">{title}</button>\n",
        "        <script>\n",
        "          document.querySelector(\"#{callback_id}\").onclick = (e) => {{\n",
        "            google.colab.kernel.invokeFunction('{callback_id}', [], {{}})\n",
        "            e.preventDefault();\n",
        "          }};\n",
        "        </script>\"\"\"\n",
        "    html = template.format(title=self._title, callback_id=callback_id)\n",
        "    return html\n",
        "\n",
        "def do_something():\n",
        "  print('here')\n",
        "\n",
        "InvokeButton('click me', do_something)"
      ],
      "metadata": {
        "id": "2UWd2sy0iUjR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "7d56ff36-ad6b-4971-b0c0-9122058f91ef"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.InvokeButton at 0x7f0650d6f9a0>"
            ],
            "text/html": [
              "<button id=\"button-e8cec34b-4d2c-4ce7-89cf-859b01c5082d\">click me</button>\n",
              "        <script>\n",
              "          document.querySelector(\"#button-e8cec34b-4d2c-4ce7-89cf-859b01c5082d\").onclick = (e) => {\n",
              "            google.colab.kernel.invokeFunction('button-e8cec34b-4d2c-4ce7-89cf-859b01c5082d', [], {})\n",
              "            e.preventDefault();\n",
              "          };\n",
              "        </script>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from IPython.display import Image\n",
        "\n",
        "# Load the pre-trained ImageNet model\n",
        "model = tf.keras.applications.MobileNetV2()\n",
        "\n",
        "# Define a function for taking a photo\n",
        "def take_photo():\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    ret, frame = cap.read()\n",
        "    filename = 'photo.jpg'\n",
        "    cv2.imwrite(filename, frame)\n",
        "    cap.release()\n",
        "    return filename\n",
        "\n",
        "# Define a function for analyzing the image using the ImageNet model\n",
        "def analyze_image(filename):\n",
        "    # Load the image\n",
        "    img = tf.keras.preprocessing.image.load_img(filename, target_size=(224, 224))\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    # Expand the dimensions of the image so that it can be fed to the model\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    # Preprocess the image\n",
        "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
        "    # Make predictions on the image using the model\n",
        "    predictions = model.predict(img_array)\n",
        "    # Decode the predictions\n",
        "    decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=3)\n",
        "    # Print the decoded predictions\n",
        "    for pred in decoded_predictions[0]:\n",
        "        print(\"{:<20} {:.2%}\".format(pred[1], pred[2]))\n",
        "    # Save the decoded predictions to a file\n",
        "    with open(\"image_analysis_results.txt\", \"a\") as f:\n",
        "        f.write(\"\\nImage: {}\\n\".format(filename))\n",
        "        for pred in decoded_predictions[0]:\n",
        "            f.write(\"{:<20} {:.2%}\\n\".format(pred[1], pred[2]))\n",
        "\n",
        "try:\n",
        "    filename = take_photo()\n",
        "    print('Saved to {}'.format(filename))\n",
        "    display(Image(filename))\n",
        "    analyze_image(filename)\n",
        "except Exception as err:\n",
        "    # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "    # grant the page permission to access it.\n",
        "    print(str(err))\n"
      ],
      "metadata": {
        "id": "-UnuoFrOi4TP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "517d62f6-d988-4d8f-c85c-9552abe8f951"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenCV(4.7.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:783: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s git://github.com/jakevdp/PythonDataScienceHandbook.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "metadata": {
        "id": "Kfw_oC5rjKAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba0c599-f623-44cf-bda4-a797b8932ebc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cloned-repo'...\n",
            "warning: --local is ignored\n",
            "^C\n",
            "[Errno 2] No such file or directory: 'cloned-repo'\n",
            "/content\n",
            "drive  sample_data  servers.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch a single <1MB file using the raw GitHub URL.\n",
        "!curl --remote-name \\\n",
        "     -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "     --location https://api.github.com/repos/jakevdp/PythonDataScienceHandbook/contents/notebooks/data/california_cities.csv"
      ],
      "metadata": {
        "id": "HvK6Gns7jKAq",
        "outputId": "8fb72deb-e4ae-4787-9558-699dd545fcc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 59658  100 59658    0     0   253k      0 --:--:-- --:--:-- --:--:--  253k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%javascript\n",
        "(async function() {\n",
        "  const result = await google.colab.kernel.invokeFunction(\n",
        "    'notebook.Concat', // The callback name.\n",
        "    ['hello', 'world!'], // The arguments.\n",
        "    {}); // kwargs\n",
        "  const text = result.data['application/json'];\n",
        "  document.querySelector(\"#output-area\").appendChild(document.createTextNode(text.result));\n",
        "})();"
      ],
      "metadata": {
        "id": "3CWcma6X_KUZ",
        "outputId": "01c53f72-ab42-4038-cb7b-c94859b41b5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async function() {\n",
              "  const result = await google.colab.kernel.invokeFunction(\n",
              "    'notebook.Concat', // The callback name.\n",
              "    ['hello', 'world!'], // The arguments.\n",
              "    {}); // kwargs\n",
              "  const text = result.data['application/json'];\n",
              "  document.querySelector(\"#output-area\").appendChild(document.createTextNode(text.result));\n",
              "})();\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "import uuid\n",
        "from google.colab import output\n",
        "\n",
        "class InvokeButton(object):\n",
        "  def __init__(self, title, callback):\n",
        "    self._title = title\n",
        "    self._callback = callback\n",
        "\n",
        "  def _repr_html_(self):\n",
        "    callback_id = 'button-' + str(uuid.uuid4())\n",
        "    output.register_callback(callback_id, self._callback)\n",
        "\n",
        "    template = \"\"\"<button id=\"{callback_id}\">{title}</button>\n",
        "        <script>\n",
        "          document.querySelector(\"#{callback_id}\").onclick = (e) => {{\n",
        "            google.colab.kernel.invokeFunction('{callback_id}', [], {{}})\n",
        "            e.preventDefault();\n",
        "          }};\n",
        "        </script>\"\"\"\n",
        "    html = template.format(title=self._title, callback_id=callback_id)\n",
        "    return html\n",
        "\n",
        "def do_something():\n",
        "  print('here')\n",
        "\n",
        "InvokeButton('click me', do_something)"
      ],
      "metadata": {
        "id": "miwf9IUL_KUb",
        "outputId": "19d6713a-8837-4997-ff56-1d5402ae5073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.InvokeButton at 0x7f065179da00>"
            ],
            "text/html": [
              "<button id=\"button-36ab9ec2-a9e6-4e41-b3ff-71db3692c830\">click me</button>\n",
              "        <script>\n",
              "          document.querySelector(\"#button-36ab9ec2-a9e6-4e41-b3ff-71db3692c830\").onclick = (e) => {\n",
              "            google.colab.kernel.invokeFunction('button-36ab9ec2-a9e6-4e41-b3ff-71db3692c830', [], {})\n",
              "            e.preventDefault();\n",
              "          };\n",
              "        </script>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "here\n",
            "here\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nowa sekcja"
      ],
      "metadata": {
        "id": "B6KBVZGa-spn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nowa sekcja"
      ],
      "metadata": {
        "id": "am6x_kT3-tJY"
      }
    }
  ]
}